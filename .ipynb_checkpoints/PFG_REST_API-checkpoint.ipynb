{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REST API Search Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Método de consulta de tweets históricos (hasta una semana) basándose en varios criterios, es muy adecuado para un análisis estático."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga inicial de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Servicio\n",
      "[nltk_data]     Técnico\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from requests_oauthlib import OAuth1\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "consumer_key='ynSB0dFvqPl3xRU7AmYk39rGT'\n",
    "consumer_secret='6alIXTKSxf0RE57QK3fDQ8dxdvlsVr1IRsHDZmoSlMx96YKBFD'\n",
    "access_token='966591013182722049-BVXW14Hf5s6O2oIwS3vtJ3S3dOsKLbY'\n",
    "access_token_secret='829DTKPjmwsSytmp1ky9fMCJkjV0LZ04TbL9oqHGV6cDm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte en la que se importa las librerías necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'carnaval tenerife -filter:retweets AND -filter:replies'\n",
    "url = 'https://api.Twitter.com/1.1/search/tweets.json'\n",
    "pms = {'q' : q, 'count' : 100, 'lang' : 'es', 'result_type': 'recent'} \n",
    "auth = OAuth1(consumer_key, consumer_secret, access_token,access_token_secret)\n",
    "#res = requests.get(url, params = pms, auth=auth)\n",
    "#esta parte del código se utiliza realmente en la paginación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sección de código que realiza la consulta **q** mediante la api de twitter utilizando los parámetros **pms**. Después, se crea una variable **auth** que corresponde a los datos exigidos por la API para conectarse que son *Las claves y los tokens de acceso.*\n",
    "Por último se realiza la petición utilizando todos los datos necesarios por medio de una función de la librería requests **(request.get)** el resultado se vuelca en la variable **res**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets = res.json()\n",
    "#esta parte del código se utiliza realmente en la paginación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si la conección es correcta se recuperarán varios documentos que se pueden convertir a json. En el formato json es en el cual extraeremos la información que nos importa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos para más de 100 tweets (Paginación)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como twitter te permite obtener hasta 100 tweets por llamada, si queremos recuperar más, necesitamos recordar los IDs de los tweets ya descargados para no repetir tweets en las siguientes llamadas. Esto es la paginación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = \"baseDeDatos\"\n",
    "collection_name = \"coleccion\"\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client[database_name]\n",
    "collection = db[collection_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MongoDB** *es una base de datos NoSQL ágil orientado a documentos, esto significa que en lugar de guardar los datos en tablas como se hace en las bbdd relacionales, MongoDB guarda estructuras de datos en documentos similares a JSON con un esquema dinámico.*\n",
    "En nuestro caso importamos la librería para usar el cliente y creamos una base de datos y una colección a raíz de la base de datos. Ya cambiaré los nombres de **database_name** y **collection_name**. <font color='red'>falta establecer el nombre de la base de datos y el nombre de la colección</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection status: OK\n",
      "Connection status: OK\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f3bd2acec06a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'statuses'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mpms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'max_id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mcollection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert_many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'statuses'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "pages_counter = 0\n",
    "number_of_pages = 100\n",
    "while pages_counter < number_of_pages:\n",
    "    pages_counter += 1\n",
    "    res = requests.get(url, params = pms, auth=auth)\n",
    "    print(\"Connection status: %s\" % res.reason)\n",
    "    tweets = res.json()\n",
    "    ids = [i['id'] for i in tweets['statuses']]\n",
    "    pms['max_id'] = min(ids) - 1\n",
    "    collection.insert_many(tweets['statuses'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código para la paginación consiste en un bucle que se repetirá tantas veces como el número aproximado de tweets que queramos recuperar de twitter. Dentro del bucle se realiza la *consulta* (**requests.get**) y se guarda en la variable tweets con formato json (igual que se hacía antes de la paginación)\n",
    "Después, para implementar lo que es realmente la paginación; \n",
    "- Se recolectan todos los **ids** de los tweets recogidos mediante el **get**.\n",
    "- Se almacena en **i** todos los **ids** de todos los tweets.\n",
    "- Se establece en **pms** como el *id mayor*, el *id mínimo* de **i** -1 (porque se incluiría y después se duplica)\n",
    "- Por último se inserta en la base de datos (Con **insert_many**) todos los tweets que han sido recuperados en esta *ronda*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#client = MongoClient('mongodb://localhost:27017/')\n",
    "#db = client['db']\n",
    "#collection = db['collection']\n",
    "documents = []\n",
    "for doc in collection.find():\n",
    "    documents.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que se hace a continuación es utilizar la base de datos de mongo en la que se ha estado almacenando los tweets para volcar la información de forma tabular, donde las columnas indican los nombres de los nodos del documento y las filas representan los datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>contributors</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>geo</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>...</th>\n",
       "      <th>lang</th>\n",
       "      <th>metadata</th>\n",
       "      <th>place</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5ae9b364b72f4e17889bded1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Thu Apr 26 09:00:05 +0000 2018</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>989428892510359552</td>\n",
       "      <td>989428892510359552</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;a href=\"http://www.coosto.com\" rel=\"nofollow\"...</td>\n",
       "      <td>Throwback Thursday! 7 t/m 18 Februari was Sant...</td>\n",
       "      <td>True</td>\n",
       "      <td>{'id': 112377239, 'id_str': '112377239', 'name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5ae9b364b72f4e17889bded2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Thu Apr 26 09:00:05 +0000 2018</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>989428892007092224</td>\n",
       "      <td>989428892007092224</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;a href=\"http://www.coosto.com\" rel=\"nofollow\"...</td>\n",
       "      <td>Throwback Thursday! 7 t/m 18 Februari was Sant...</td>\n",
       "      <td>True</td>\n",
       "      <td>{'id': 886795129, 'id_str': '886795129', 'name...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id contributors coordinates  \\\n",
       "0  5ae9b364b72f4e17889bded1         None        None   \n",
       "1  5ae9b364b72f4e17889bded2         None        None   \n",
       "\n",
       "                       created_at  \\\n",
       "0  Thu Apr 26 09:00:05 +0000 2018   \n",
       "1  Thu Apr 26 09:00:05 +0000 2018   \n",
       "\n",
       "                                            entities  favorite_count  \\\n",
       "0  {'hashtags': [], 'symbols': [], 'user_mentions...               1   \n",
       "1  {'hashtags': [], 'symbols': [], 'user_mentions...               0   \n",
       "\n",
       "   favorited   geo                  id              id_str  \\\n",
       "0      False  None  989428892510359552  989428892510359552   \n",
       "1      False  None  989428892007092224  989428892007092224   \n",
       "\n",
       "                         ...                         lang  \\\n",
       "0                        ...                           en   \n",
       "1                        ...                           en   \n",
       "\n",
       "                                            metadata place possibly_sensitive  \\\n",
       "0  {'iso_language_code': 'en', 'result_type': 're...  None              False   \n",
       "1  {'iso_language_code': 'en', 'result_type': 're...  None              False   \n",
       "\n",
       "  retweet_count  retweeted                                             source  \\\n",
       "0             0      False  <a href=\"http://www.coosto.com\" rel=\"nofollow\"...   \n",
       "1             0      False  <a href=\"http://www.coosto.com\" rel=\"nofollow\"...   \n",
       "\n",
       "                                                text truncated  \\\n",
       "0  Throwback Thursday! 7 t/m 18 Februari was Sant...      True   \n",
       "1  Throwback Thursday! 7 t/m 18 Februari was Sant...      True   \n",
       "\n",
       "                                                user  \n",
       "0  {'id': 112377239, 'id_str': '112377239', 'name...  \n",
       "1  {'id': 886795129, 'id_str': '886795129', 'name...  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(documents)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este paso se crea un Dataframe usando la lista de documentos que hemos construido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos gustaría analizar los sentimientos de los tweets que son escritos por la gente desde sus diferentes dispositivos. Por lo tanto, debemos deshacernos de los tweets compuestos por bots, páginas web, servicios de envío automatizado, etc. No podemos identificar esos tweets al 100%, pero es bastante buena suposición sería seleccionar tweets publicados desde dispositivos físicos, es decir, iPhones, Teléfonos Android, ordenadores de sobremesa y portátiles. \n",
    "Los documentos de Twitter tienen una característica interesante, ya que mantienen la información sobre la fuente de la creación del tweet. Cada vez que alguien usa un dispositivo para componer un tweet, el se mantiene la información al respecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Anaconda\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "df['tweet_source'] = df['source'].apply(lambda x:\n",
    "                                        BeautifulSoup(x).get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta linea de código vamos a crear una nueva columna en el data Frame df que se llama tweet_source y ahí vamos a poner lo que había en la columna source pero con la información que necesitamos, es decir, la fuente del tweet.\n",
    "Ahora bien, sólo nos interesan los dispositivos. La información sobre los dispositivos es muy clara: encontraremos fuentes de tweets como Twitter para iPhone, Twitter para Android, Twitter Web Client, Twitter para BlackBerry, Twitter para Mac, Twitter para Windows, etc. Los nombres de los dispositivos comienzan con la palabra \"Twitter\". Utilizaremos esta propiedad para abordar nuestra segunda cuestión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = list(set(df[df['tweet_source'].str.startswith('Twitter')]['tweet_source']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta manera se extrae en la variable devices todas las fuentes de los tweets que comiencen por Twitter, es decir, todas las que vienen de dispositivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices.remove('Twitter Ads')\n",
    "df = df[df['tweet_source'].isin(devices)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quitamos de la lista de dispositivos todos aquellos que sean anuncios de Twitter y dejamos en el data frame sólamente aquellos twits cuya fuente sea la misma que la que tenemos en devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[~df['text'].str.contains(\"Ghana|ghana|jamaica|Jamaica|Ladbrokes|India|Pa kistan|Ghana Premier League|Vijay|Predictions|Egyptian Premier League|cricket|Kings|Caribbean Premier League|@cricbuzz|Cricinfo\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto lo que se hace en el libro (quizá yo no tenga que hacerlo) es eliminar la posibilidad de que salgan twits de Premiere League que no sea la inglesa. Hay otras Premiere League que no interesa para el estudio del libro y se quita mediante esta función utilizando las palabras clave que necesitemos. Toda esta búsqueda para la limpieza se realiza en el campo text de df (df.text)\n",
    "El código dice, en esencia, mantiene todas las filas que NO (~) tengan en la columa \"text\" las siguientes palabras (| es el operador lógico OR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOKENIZATION\n",
    "df['tokens'] = df['text'].apply(TweetTokenizer().tokenize)\n",
    "#STOPWORDS\n",
    "stopwords_vocabulary = stopwords.words('spanish') #estará en español?\n",
    "df['stopwords'] = df['tokens'].apply(lambda x: [i for i in x if i.lower() not in stopwords_vocabulary])\n",
    "#SPECIAL CHARACTERS AND STOPWORDS REMOVAL\n",
    "punctuations = list(string.punctuation)\n",
    "df['punctuation'] = df['stopwords'].apply(lambda x: [i for i in x if i not in punctuations])\n",
    "df['digits'] = df['punctuation'].apply(lambda x: [i for i in x if i[0] not in list(string.digits)])\n",
    "df['final'] = df['digits'].apply(lambda x: [i for i in x if len(i) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
